# Day 3 Keynote Margaret Mitchell

## Python, Data, and Bias

When working on image to text -> learned about how what it was doing was different from what blind folks might need

"everything is awesome" problem - since the model is trained on how people describe their photos, the model learns that everything is great and/or awesome

part of the AI training problem is frequency bias - we write more about things that are less frequent

Having an ethics team can create an 'us v them' mentality. Better to have ethics folks distributed throughout all the teams
